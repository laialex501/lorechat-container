# LoreChat Product Context

## Problem & Solution
LoreChat addresses the need for efficient information retrieval from websites by providing a conversational AI interface. Users can ask questions in natural language and receive contextual, relevant answers derived from website content.

## Core Value Propositions
1. Natural language interaction
2. Contextual understanding of website content
3. Quick, relevant answers without manual searching
4. Flexible integration with different LLM providers

## User Experience Goals
- Simple, intuitive chat interface
- Real-time, responsive interactions
- Clear user/assistant message distinction
- Maintained conversation context within session

## Key Interaction Patterns
1. Welcoming initial engagement
2. Smooth conversation flow with visual feedback
3. Formatted, readable responses with markdown support

## Performance Targets
- Response time: < 2 seconds for typical queries
- Scalability: Handle multiple concurrent users
- Error handling: Clear, user-friendly messages

## User Scenarios
1. Quick information lookup
2. Multi-turn conversations with context retention

## Success Metrics
- User experience: Response accuracy, query resolution time, session duration
- Technical: Response latency, concurrent user handling, error rate, resource utilization

## Design Principles
1. Simplicity first
2. Responsive design
3. Contextual intelligence
4. Error resilience

## Future Considerations
- Potential enhancements: Multi-language support, rich media responses, analytics
- Integration opportunities: Authentication, CMS, analytics, monitoring

## Current Limitations
- Session-only history
- No user authentication
- Text-only responses
- Development-mode vector store

## Technical Constraints
- Streamlit framework limitations
- LLM API dependencies
- Container resource limits
- Development environment restrictions
